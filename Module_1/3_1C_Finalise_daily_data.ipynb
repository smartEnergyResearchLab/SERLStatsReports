{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "This notebook will produce all the final clean daily energy data for step 3.1C of the data processing for Module 1.\n",
    "\n",
    "**This requires output from the previous steps - 2, 3.1A and 3.1B - so run those notebooks first**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required user input**\n",
    "\n",
    "Update the cell below once each for the full years of 2019, 2020, 2021, and run the entire notebook for each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2021' # Update year - this is the year of data you are working on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change these.\n",
    "\n",
    "# Source data files from steps 2, 3.1A and 3.1B\n",
    "source_directory_gas='Step_3_1_Outputs'\n",
    "source_directory_elec='Step_3_1_Outputs'\n",
    "source_filename_gas = 'Step_3_1A_Gas_'+year+'_daily.csv'\n",
    "source_filename_elec = 'Step_3_1B_Elec_'+year+'_daily.csv'\n",
    "source_directory_temperature = 'Step_2_Outputs'\n",
    "source_filename_temperature = 'Step_2_Temp_'+str(year)+'_daily.csv'\n",
    "\n",
    "index_start_date=year+'-01-01' # Start date for the output's index to include.\n",
    "index_end_date=year+'-12-31' # End date for the output's index to include.\n",
    "\n",
    "output_directory= 'Module_1_final_outputs'\n",
    "output_filename='annual_report_sm_daily_'+year+'.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the source csvs\n",
    "gas_daily_data = pd.read_csv(os.path.join(source_directory_gas,source_filename_gas),\n",
    "                             index_col=['PUPRN','Read_date_effective_local'],\n",
    "                            parse_dates=['Read_date_effective_local'])\n",
    "elec_daily_data = pd.read_csv(os.path.join(source_directory_elec,source_filename_elec),\n",
    "                              index_col=['PUPRN','Read_date_effective_local'],\n",
    "                             parse_dates=['Read_date_effective_local'])\n",
    "\n",
    "#Get list of grid_cells mapped to PUPRN, from the participant data file\n",
    "puprn_to_grid_cell = pd.read_csv(os.path.join(locations.serl_data_path,locations.participant_data_file),\n",
    "                                 usecols=['PUPRN','grid_cell'])\n",
    "\n",
    "# Load the temperature data\n",
    "temperature_daily_data = pd.read_csv(os.path.join(source_directory_temperature,source_filename_temperature),\n",
    "                                     parse_dates=['Read_date_effective_local'],\n",
    "                                     index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the energy together, keeping everything\n",
    "energy_daily_data = pd.merge(elec_daily_data,gas_daily_data,left_index=True,right_index=True,how='outer')\n",
    "num_PUPRNS = len(energy_daily_data.index.get_level_values('PUPRN').unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this stage, we have all the clean readings for electricity and gas, net for electricity, based on hh data wherever possible, otherwise daily, otherwise missing.\n",
    "# Rows for dates with no clean gas or electricity for a particular PUPRN are still missing for that particular PUPRN. \n",
    "# Final steps are to fill those in for each PUPRN, so there are rows of Nans for the full year for each PUPRN.\n",
    "\n",
    "# First, create the template index - a complete year.\n",
    "date_index_new = pd.date_range(index_start_date,index_end_date,freq='D')\n",
    "# Then a blank df based on it\n",
    "energy_daily_data_final = pd.DataFrame(index=pd.MultiIndex.from_product([energy_daily_data.index.get_level_values('PUPRN').unique(),date_index_new],\n",
    "                                                             names=['PUPRN','Read_date_effective_local']))\n",
    "\n",
    "# Join onto it\n",
    "energy_daily_data_final = pd.merge(energy_daily_data_final,energy_daily_data,left_index=True,right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join on the temperature data\n",
    "# Prep the temperature data for joining - # Get it ready for each PUPRN\n",
    "temperature_daily_data_per_puprn = pd.merge(temperature_daily_data, puprn_to_grid_cell, on='grid_cell',how='outer')\n",
    "temperature_daily_data_per_puprn.set_index(['PUPRN','Read_date_effective_local'],inplace=True)\n",
    "energy_daily_data_final = pd.merge(energy_daily_data_final,temperature_daily_data_per_puprn[['mean_temp_C','hdd']],left_index=True,right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic data quality checks\n",
    "# No Nans; correct length; monotonically increasing; no duplicate rows.\n",
    "nancount = energy_daily_data_final[['mean_temp_C','hdd']].isnull().sum().sum()\n",
    "in_sequence = energy_daily_data_final.index.is_monotonic_increasing \n",
    "no_duplicate_rows = energy_daily_data_final.index.is_unique\n",
    "wrong_length = energy_daily_data_final.shape[0] - num_PUPRNS*len(date_index_new)\n",
    "\n",
    "if (nancount== 0 and in_sequence==True and no_duplicate_rows== True and wrong_length==0):\n",
    "    print('Data is sorted by PUPRN then Read_date_effective_local, has no duplicates (no duplicate PUPRN and Read_date_effective_local combinations), and has no missing rows of mean_temp_C or hdd data.')\n",
    "else:\n",
    "    print(\"WARNING! Your data has one or more issues:\\n- This many mean_temp_C or hdd missing values (should be zero):\",\n",
    "          nancount,\n",
    "          \"\\n- Index out of sequence:\",\n",
    "          (not in_sequence),\n",
    "          \"\\n- Duplicate rows (duplicate PUPRN and Read_date_effective_local combination):\",\n",
    "          (not no_duplicate_rows),\n",
    "          \"\\n- This many rows too long (or too short, if negative):\",\n",
    "          wrong_length,\n",
    "          \"\\nCheck and fix before continuing.\")\n",
    "print(\"\\nHere's the tail of your new dataframe:\\n\")\n",
    "energy_daily_data_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save: This is the output of final daily data from Module 1.\n",
    "if not os.path.exists(os.path.join(output_directory)):\n",
    "    os.makedirs(os.path.join(output_directory))\n",
    "energy_daily_data_final.to_csv(os.path.join(output_directory,output_filename),index=True)\n",
    "print(\"Job done. Everything saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
